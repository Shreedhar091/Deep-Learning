{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning using InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#######################################################################################\n",
    "# 1.0 Call libraries\n",
    "import cv2     # Image manipulation module\n",
    "               #  of OpenCV library\n",
    "\n",
    "# 1.2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 1.3\n",
    "from keras.models import  Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "\n",
    "# 1.4 We will use these callbacks()\n",
    "# 1.4.1 For storing model with minimum loss after every epoch\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "# 1.4.2 Stop training when val_loss does not decrease enough\n",
    "from keras.callbacks import EarlyStopping\n",
    "# 1.4.3 Reduce learning rate when val_loss stops improving\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# 1.5\n",
    "import matplotlib.pyplot as plt\n",
    "import os, time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.0 Define constants\n",
    "img_height = 150\n",
    "img_width = 150\n",
    "img_channels = 3\n",
    "img_dim = (img_height, img_width, img_channels)\n",
    "img_size = (img_height, img_width)\n",
    "batch_size = 5\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"D:/ShreeTechnical/MLDL/Classes/EX/ex12/train/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2295, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.1 Read filenames vs target-values\n",
    "train_set = pd.read_csv('D:/ShreeTechnical/MLDL/Classes/EX/ex12/train_labels.csv')\n",
    "train_set.head()     # Ist coluumn is 'name' ie filename,\n",
    "                     # IInd column is 'invasive'\n",
    "train_set.shape      # (2295, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 Define a function that returns\n",
    "#     i) A list of files with full-path\n",
    "#    ii) A data frame, with filenames (with full path) & target-values\n",
    "#   iii) A 1D array of labels--invasive or non-invasive\n",
    "def load_train(path):\n",
    "    # 3.2.1 An empty list to store full filenames\n",
    "    train_files = []\n",
    "    # 3.2.2 Get an array of image labels\n",
    "    train_label = np.array(train_set['invasive'])\n",
    "    # 3.2.3. We need not peep into folder\n",
    "    #        Our filenames are 1.jpg, 2.jpg etc\n",
    "    #\n",
    "    for i in range(train_set.shape[0]):\n",
    "        # 3.2.4 Create a filename with path\n",
    "        filename=str(int(train_set.iloc[i,0])) +'.jpg'\n",
    "        # 3.2.5 Append it to filename list\n",
    "        train_files.append(path + filename)\n",
    "\n",
    "    # 3.2.6 Finally replace existing values in 'name' column\n",
    "    #       with filepaths\n",
    "    train_set['name'] = train_files\n",
    "    # 3.2.7 Return the three objects\n",
    "    return train_files, train_set, train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3 Now use load_train() to get desired output\n",
    "train_files, train_set, train_label = load_train(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.4 Check all three output\n",
    "train_label[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>invasive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D:/ShreeTechnical/MLDL/Classes/EX/ex12/train/1...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D:/ShreeTechnical/MLDL/Classes/EX/ex12/train/2...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D:/ShreeTechnical/MLDL/Classes/EX/ex12/train/3...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D:/ShreeTechnical/MLDL/Classes/EX/ex12/train/4...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D:/ShreeTechnical/MLDL/Classes/EX/ex12/train/5...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  invasive\n",
       "0  D:/ShreeTechnical/MLDL/Classes/EX/ex12/train/1...         0\n",
       "1  D:/ShreeTechnical/MLDL/Classes/EX/ex12/train/2...         0\n",
       "2  D:/ShreeTechnical/MLDL/Classes/EX/ex12/train/3...         1\n",
       "3  D:/ShreeTechnical/MLDL/Classes/EX/ex12/train/4...         0\n",
       "4  D:/ShreeTechnical/MLDL/Classes/EX/ex12/train/5...         1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:/ShreeTechnical/MLDL/Classes/EX/ex12/train/1.jpg',\n",
       " 'D:/ShreeTechnical/MLDL/Classes/EX/ex12/train/2.jpg',\n",
       " 'D:/ShreeTechnical/MLDL/Classes/EX/ex12/train/3.jpg',\n",
       " 'D:/ShreeTechnical/MLDL/Classes/EX/ex12/train/4.jpg',\n",
       " 'D:/ShreeTechnical/MLDL/Classes/EX/ex12/train/5.jpg']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.5 We assume our data is shuffled enough\n",
    "# 3.5.1 Here is our train data\n",
    "x_train = train_set.iloc[:2000,:]     # x_train is pandas dataframe\n",
    "y_train =train_label[:2000]           # Numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.5.2 And our validation data\n",
    "x_valid = train_set.iloc[2000:,:]     # 295 images\n",
    "y_valid =train_label[2000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Shree\\Shri\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# 4.0 Quickly construct a simple Sequential model\n",
    "\n",
    "# 4.1 Download inception weights and create its model\n",
    "#     File size is 88MB. Download is one time to folders\n",
    "#     /home/ashok/.keras/models\n",
    "\n",
    "base_model = InceptionV3(include_top=False,\n",
    "                         weights='imagenet',\n",
    "                         input_shape=img_dim\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 150, 150, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 74, 74, 32)   864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 74, 74, 32)   96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 74, 74, 32)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 72, 72, 32)   9216        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 72, 72, 32)   96          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 72, 72, 32)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 72, 72, 64)   18432       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 72, 72, 64)   192         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 72, 72, 64)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 35, 35, 64)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 35, 35, 80)   240         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 35, 35, 80)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 33, 33, 192)  138240      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 33, 33, 192)  576         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 33, 33, 192)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 16, 64)   192         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16, 16, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 96)   55296       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 16, 16, 48)   144         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 16, 16, 48)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 16, 16, 192)  0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 64)   76800       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 96)   82944       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 16, 16, 64)   192         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 96)   288         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 16, 32)   96          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 16, 16, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 96)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16, 16, 32)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_6[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "                                                                 activation_11[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 64)   192         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 16, 64)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 96)   55296       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 16, 16, 48)   144         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 16, 16, 48)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 16, 16, 64)   76800       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 16, 16, 96)   82944       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 64)   192         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 16, 16, 96)   288         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 16, 16, 64)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 16, 16, 96)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_13[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 16, 16, 64)   192         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 16, 16, 64)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 16, 16, 96)   55296       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 16, 16, 48)   144         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 16, 16, 48)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 16, 16, 64)   76800       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 16, 16, 96)   82944       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 16, 16, 64)   192         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 16, 16, 96)   288         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 16, 16, 64)   192         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 16, 16, 64)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 16, 16, 96)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 16, 16, 64)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_20[0][0]              \n",
      "                                                                 activation_22[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "                                                                 activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 16, 16, 64)   192         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 16, 16, 64)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 16, 16, 96)   55296       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 16, 16, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 16, 16, 96)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 7, 7, 96)     82944       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 7, 7, 384)    1152        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 7, 7, 96)     288         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 7, 7, 384)    0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 7, 7, 96)     0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_27[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 7, 7, 128)    114688      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 7, 7, 128)    114688      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 7, 7, 128)    384         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 7, 7, 128)    384         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 7, 7, 128)    0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 7, 7, 128)    0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 7, 7, 192)    172032      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 7, 7, 192)    172032      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 7, 7, 192)    576         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 7, 7, 192)    576         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 7, 7, 192)    0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 7, 7, 192)    0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_31[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 7, 7, 160)    179200      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 7, 7, 160)    179200      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 7, 7, 160)    480         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 7, 7, 160)    480         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 160)    0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 160)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 7, 7, 192)    215040      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 7, 7, 192)    215040      activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 7, 7, 192)    576         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 7, 7, 192)    576         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 192)    0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 192)    0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_41[0][0]              \n",
      "                                                                 activation_44[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "                                                                 activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 7, 7, 160)    179200      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 7, 7, 160)    179200      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 7, 7, 160)    480         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 7, 7, 160)    480         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 7, 7, 160)    0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 7, 7, 160)    0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 7, 7, 192)    215040      activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 7, 7, 192)    215040      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 7, 7, 192)    576         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 7, 7, 192)    576         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 7, 7, 192)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 7, 7, 192)    0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_51[0][0]              \n",
      "                                                                 activation_54[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "                                                                 activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 7, 7, 192)    258048      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 7, 7, 192)    258048      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 7, 7, 192)    576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 7, 7, 192)    0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_61[0][0]              \n",
      "                                                                 activation_64[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "                                                                 activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 7, 7, 192)    576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 7, 7, 192)    0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 7, 7, 192)    258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 7, 7, 192)    576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 7, 7, 192)    0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 7, 7, 192)    258048      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 7, 7, 192)    576         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 7, 7, 192)    576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 7, 7, 192)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 7, 7, 192)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 3, 3, 320)    552960      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 3, 3, 192)    331776      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 3, 3, 320)    960         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 3, 3, 192)    576         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 3, 3, 320)    0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 3, 3, 192)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_72[0][0]              \n",
      "                                                                 activation_76[0][0]              \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 3, 3, 448)    1344        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 3, 3, 448)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 3, 3, 384)    1548288     activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 3, 3, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 3, 3, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 3, 3, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 3, 3, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 3, 3, 384)    442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 3, 3, 384)    442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 3, 3, 384)    442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 3, 3, 384)    442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 3, 3, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 3, 3, 384)    1152        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 3, 3, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 3, 3, 384)    1152        conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 3, 3, 192)    245760      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 3, 3, 320)    960         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 3, 3, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 3, 3, 384)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 3, 3, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 3, 3, 384)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 3, 3, 192)    576         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 3, 3, 320)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_79[0][0]              \n",
      "                                                                 activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 3, 3, 768)    0           activation_83[0][0]              \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 3, 3, 192)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_77[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 3, 3, 448)    1344        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 3, 3, 448)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 3, 3, 384)    1548288     activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 3, 3, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 3, 3, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 3, 3, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 3, 3, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 3, 3, 384)    442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 3, 3, 384)    442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 3, 3, 384)    442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 3, 3, 384)    442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 3, 3, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 3, 3, 384)    1152        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 3, 3, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 3, 3, 384)    1152        conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 3, 3, 192)    393216      average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 3, 3, 320)    960         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 3, 3, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 3, 3, 384)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 3, 3, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 3, 3, 384)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 3, 3, 192)    576         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 3, 3, 320)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_88[0][0]              \n",
      "                                                                 activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 3, 3, 768)    0           activation_92[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 3, 3, 192)    0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_86[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 activation_94[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 21,768,352\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 4.2 Look at the model\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "311"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4.3 Total number of layers are:\n",
    "len(base_model.layers)      # 311"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'input_1')\n",
      "(1, 'conv2d_1')\n",
      "(2, 'batch_normalization_1')\n",
      "(3, 'activation_1')\n",
      "(4, 'conv2d_2')\n",
      "(5, 'batch_normalization_2')\n",
      "(6, 'activation_2')\n",
      "(7, 'conv2d_3')\n",
      "(8, 'batch_normalization_3')\n",
      "(9, 'activation_3')\n",
      "(10, 'max_pooling2d_1')\n",
      "(11, 'conv2d_4')\n",
      "(12, 'batch_normalization_4')\n",
      "(13, 'activation_4')\n",
      "(14, 'conv2d_5')\n",
      "(15, 'batch_normalization_5')\n",
      "(16, 'activation_5')\n",
      "(17, 'max_pooling2d_2')\n",
      "(18, 'conv2d_9')\n",
      "(19, 'batch_normalization_9')\n",
      "(20, 'activation_9')\n",
      "(21, 'conv2d_7')\n",
      "(22, 'conv2d_10')\n",
      "(23, 'batch_normalization_7')\n",
      "(24, 'batch_normalization_10')\n",
      "(25, 'activation_7')\n",
      "(26, 'activation_10')\n",
      "(27, 'average_pooling2d_1')\n",
      "(28, 'conv2d_6')\n",
      "(29, 'conv2d_8')\n",
      "(30, 'conv2d_11')\n",
      "(31, 'conv2d_12')\n",
      "(32, 'batch_normalization_6')\n",
      "(33, 'batch_normalization_8')\n",
      "(34, 'batch_normalization_11')\n",
      "(35, 'batch_normalization_12')\n",
      "(36, 'activation_6')\n",
      "(37, 'activation_8')\n",
      "(38, 'activation_11')\n",
      "(39, 'activation_12')\n",
      "(40, 'mixed0')\n",
      "(41, 'conv2d_16')\n",
      "(42, 'batch_normalization_16')\n",
      "(43, 'activation_16')\n",
      "(44, 'conv2d_14')\n",
      "(45, 'conv2d_17')\n",
      "(46, 'batch_normalization_14')\n",
      "(47, 'batch_normalization_17')\n",
      "(48, 'activation_14')\n",
      "(49, 'activation_17')\n",
      "(50, 'average_pooling2d_2')\n",
      "(51, 'conv2d_13')\n",
      "(52, 'conv2d_15')\n",
      "(53, 'conv2d_18')\n",
      "(54, 'conv2d_19')\n",
      "(55, 'batch_normalization_13')\n",
      "(56, 'batch_normalization_15')\n",
      "(57, 'batch_normalization_18')\n",
      "(58, 'batch_normalization_19')\n",
      "(59, 'activation_13')\n",
      "(60, 'activation_15')\n",
      "(61, 'activation_18')\n",
      "(62, 'activation_19')\n",
      "(63, 'mixed1')\n",
      "(64, 'conv2d_23')\n",
      "(65, 'batch_normalization_23')\n",
      "(66, 'activation_23')\n",
      "(67, 'conv2d_21')\n",
      "(68, 'conv2d_24')\n",
      "(69, 'batch_normalization_21')\n",
      "(70, 'batch_normalization_24')\n",
      "(71, 'activation_21')\n",
      "(72, 'activation_24')\n",
      "(73, 'average_pooling2d_3')\n",
      "(74, 'conv2d_20')\n",
      "(75, 'conv2d_22')\n",
      "(76, 'conv2d_25')\n",
      "(77, 'conv2d_26')\n",
      "(78, 'batch_normalization_20')\n",
      "(79, 'batch_normalization_22')\n",
      "(80, 'batch_normalization_25')\n",
      "(81, 'batch_normalization_26')\n",
      "(82, 'activation_20')\n",
      "(83, 'activation_22')\n",
      "(84, 'activation_25')\n",
      "(85, 'activation_26')\n",
      "(86, 'mixed2')\n",
      "(87, 'conv2d_28')\n",
      "(88, 'batch_normalization_28')\n",
      "(89, 'activation_28')\n",
      "(90, 'conv2d_29')\n",
      "(91, 'batch_normalization_29')\n",
      "(92, 'activation_29')\n",
      "(93, 'conv2d_27')\n",
      "(94, 'conv2d_30')\n",
      "(95, 'batch_normalization_27')\n",
      "(96, 'batch_normalization_30')\n",
      "(97, 'activation_27')\n",
      "(98, 'activation_30')\n",
      "(99, 'max_pooling2d_3')\n",
      "(100, 'mixed3')\n",
      "(101, 'conv2d_35')\n",
      "(102, 'batch_normalization_35')\n",
      "(103, 'activation_35')\n",
      "(104, 'conv2d_36')\n",
      "(105, 'batch_normalization_36')\n",
      "(106, 'activation_36')\n",
      "(107, 'conv2d_32')\n",
      "(108, 'conv2d_37')\n",
      "(109, 'batch_normalization_32')\n",
      "(110, 'batch_normalization_37')\n",
      "(111, 'activation_32')\n",
      "(112, 'activation_37')\n",
      "(113, 'conv2d_33')\n",
      "(114, 'conv2d_38')\n",
      "(115, 'batch_normalization_33')\n",
      "(116, 'batch_normalization_38')\n",
      "(117, 'activation_33')\n",
      "(118, 'activation_38')\n",
      "(119, 'average_pooling2d_4')\n",
      "(120, 'conv2d_31')\n",
      "(121, 'conv2d_34')\n",
      "(122, 'conv2d_39')\n",
      "(123, 'conv2d_40')\n",
      "(124, 'batch_normalization_31')\n",
      "(125, 'batch_normalization_34')\n",
      "(126, 'batch_normalization_39')\n",
      "(127, 'batch_normalization_40')\n",
      "(128, 'activation_31')\n",
      "(129, 'activation_34')\n",
      "(130, 'activation_39')\n",
      "(131, 'activation_40')\n",
      "(132, 'mixed4')\n",
      "(133, 'conv2d_45')\n",
      "(134, 'batch_normalization_45')\n",
      "(135, 'activation_45')\n",
      "(136, 'conv2d_46')\n",
      "(137, 'batch_normalization_46')\n",
      "(138, 'activation_46')\n",
      "(139, 'conv2d_42')\n",
      "(140, 'conv2d_47')\n",
      "(141, 'batch_normalization_42')\n",
      "(142, 'batch_normalization_47')\n",
      "(143, 'activation_42')\n",
      "(144, 'activation_47')\n",
      "(145, 'conv2d_43')\n",
      "(146, 'conv2d_48')\n",
      "(147, 'batch_normalization_43')\n",
      "(148, 'batch_normalization_48')\n",
      "(149, 'activation_43')\n",
      "(150, 'activation_48')\n",
      "(151, 'average_pooling2d_5')\n",
      "(152, 'conv2d_41')\n",
      "(153, 'conv2d_44')\n",
      "(154, 'conv2d_49')\n",
      "(155, 'conv2d_50')\n",
      "(156, 'batch_normalization_41')\n",
      "(157, 'batch_normalization_44')\n",
      "(158, 'batch_normalization_49')\n",
      "(159, 'batch_normalization_50')\n",
      "(160, 'activation_41')\n",
      "(161, 'activation_44')\n",
      "(162, 'activation_49')\n",
      "(163, 'activation_50')\n",
      "(164, 'mixed5')\n",
      "(165, 'conv2d_55')\n",
      "(166, 'batch_normalization_55')\n",
      "(167, 'activation_55')\n",
      "(168, 'conv2d_56')\n",
      "(169, 'batch_normalization_56')\n",
      "(170, 'activation_56')\n",
      "(171, 'conv2d_52')\n",
      "(172, 'conv2d_57')\n",
      "(173, 'batch_normalization_52')\n",
      "(174, 'batch_normalization_57')\n",
      "(175, 'activation_52')\n",
      "(176, 'activation_57')\n",
      "(177, 'conv2d_53')\n",
      "(178, 'conv2d_58')\n",
      "(179, 'batch_normalization_53')\n",
      "(180, 'batch_normalization_58')\n",
      "(181, 'activation_53')\n",
      "(182, 'activation_58')\n",
      "(183, 'average_pooling2d_6')\n",
      "(184, 'conv2d_51')\n",
      "(185, 'conv2d_54')\n",
      "(186, 'conv2d_59')\n",
      "(187, 'conv2d_60')\n",
      "(188, 'batch_normalization_51')\n",
      "(189, 'batch_normalization_54')\n",
      "(190, 'batch_normalization_59')\n",
      "(191, 'batch_normalization_60')\n",
      "(192, 'activation_51')\n",
      "(193, 'activation_54')\n",
      "(194, 'activation_59')\n",
      "(195, 'activation_60')\n",
      "(196, 'mixed6')\n",
      "(197, 'conv2d_65')\n",
      "(198, 'batch_normalization_65')\n",
      "(199, 'activation_65')\n",
      "(200, 'conv2d_66')\n",
      "(201, 'batch_normalization_66')\n",
      "(202, 'activation_66')\n",
      "(203, 'conv2d_62')\n",
      "(204, 'conv2d_67')\n",
      "(205, 'batch_normalization_62')\n",
      "(206, 'batch_normalization_67')\n",
      "(207, 'activation_62')\n",
      "(208, 'activation_67')\n",
      "(209, 'conv2d_63')\n",
      "(210, 'conv2d_68')\n",
      "(211, 'batch_normalization_63')\n",
      "(212, 'batch_normalization_68')\n",
      "(213, 'activation_63')\n",
      "(214, 'activation_68')\n",
      "(215, 'average_pooling2d_7')\n",
      "(216, 'conv2d_61')\n",
      "(217, 'conv2d_64')\n",
      "(218, 'conv2d_69')\n",
      "(219, 'conv2d_70')\n",
      "(220, 'batch_normalization_61')\n",
      "(221, 'batch_normalization_64')\n",
      "(222, 'batch_normalization_69')\n",
      "(223, 'batch_normalization_70')\n",
      "(224, 'activation_61')\n",
      "(225, 'activation_64')\n",
      "(226, 'activation_69')\n",
      "(227, 'activation_70')\n",
      "(228, 'mixed7')\n",
      "(229, 'conv2d_73')\n",
      "(230, 'batch_normalization_73')\n",
      "(231, 'activation_73')\n",
      "(232, 'conv2d_74')\n",
      "(233, 'batch_normalization_74')\n",
      "(234, 'activation_74')\n",
      "(235, 'conv2d_71')\n",
      "(236, 'conv2d_75')\n",
      "(237, 'batch_normalization_71')\n",
      "(238, 'batch_normalization_75')\n",
      "(239, 'activation_71')\n",
      "(240, 'activation_75')\n",
      "(241, 'conv2d_72')\n",
      "(242, 'conv2d_76')\n",
      "(243, 'batch_normalization_72')\n",
      "(244, 'batch_normalization_76')\n",
      "(245, 'activation_72')\n",
      "(246, 'activation_76')\n",
      "(247, 'max_pooling2d_4')\n",
      "(248, 'mixed8')\n",
      "(249, 'conv2d_81')\n",
      "(250, 'batch_normalization_81')\n",
      "(251, 'activation_81')\n",
      "(252, 'conv2d_78')\n",
      "(253, 'conv2d_82')\n",
      "(254, 'batch_normalization_78')\n",
      "(255, 'batch_normalization_82')\n",
      "(256, 'activation_78')\n",
      "(257, 'activation_82')\n",
      "(258, 'conv2d_79')\n",
      "(259, 'conv2d_80')\n",
      "(260, 'conv2d_83')\n",
      "(261, 'conv2d_84')\n",
      "(262, 'average_pooling2d_8')\n",
      "(263, 'conv2d_77')\n",
      "(264, 'batch_normalization_79')\n",
      "(265, 'batch_normalization_80')\n",
      "(266, 'batch_normalization_83')\n",
      "(267, 'batch_normalization_84')\n",
      "(268, 'conv2d_85')\n",
      "(269, 'batch_normalization_77')\n",
      "(270, 'activation_79')\n",
      "(271, 'activation_80')\n",
      "(272, 'activation_83')\n",
      "(273, 'activation_84')\n",
      "(274, 'batch_normalization_85')\n",
      "(275, 'activation_77')\n",
      "(276, 'mixed9_0')\n",
      "(277, 'concatenate_1')\n",
      "(278, 'activation_85')\n",
      "(279, 'mixed9')\n",
      "(280, 'conv2d_90')\n",
      "(281, 'batch_normalization_90')\n",
      "(282, 'activation_90')\n",
      "(283, 'conv2d_87')\n",
      "(284, 'conv2d_91')\n",
      "(285, 'batch_normalization_87')\n",
      "(286, 'batch_normalization_91')\n",
      "(287, 'activation_87')\n",
      "(288, 'activation_91')\n",
      "(289, 'conv2d_88')\n",
      "(290, 'conv2d_89')\n",
      "(291, 'conv2d_92')\n",
      "(292, 'conv2d_93')\n",
      "(293, 'average_pooling2d_9')\n",
      "(294, 'conv2d_86')\n",
      "(295, 'batch_normalization_88')\n",
      "(296, 'batch_normalization_89')\n",
      "(297, 'batch_normalization_92')\n",
      "(298, 'batch_normalization_93')\n",
      "(299, 'conv2d_94')\n",
      "(300, 'batch_normalization_86')\n",
      "(301, 'activation_88')\n",
      "(302, 'activation_89')\n",
      "(303, 'activation_92')\n",
      "(304, 'activation_93')\n",
      "(305, 'batch_normalization_94')\n",
      "(306, 'activation_86')\n",
      "(307, 'mixed9_1')\n",
      "(308, 'concatenate_2')\n",
      "(309, 'activation_94')\n",
      "(310, 'mixed10')\n"
     ]
    }
   ],
   "source": [
    "# 4.4 Look at layer names again\n",
    "for i,layer in enumerate(base_model.layers):\n",
    "    print((i,layer.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.5 Initialise: Freeze all layers from training\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.6 Make layers 300 onwards available for training\n",
    "#     Increasing training layers may reduce speed\n",
    "#     as also accuracy\n",
    "\n",
    "for layer in base_model.layers[300:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# 4.7 Quick Check\n",
    "for layer in base_model.layers:\n",
    "    print(layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Shree\\Shri\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_v3 (Model)         (None, 3, 3, 2048)        21802784  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 21,804,833\n",
      "Trainable params: 2,561\n",
      "Non-trainable params: 21,802,272\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 4.8 Continue to build model\n",
    "my_new_model = Sequential()\n",
    "my_new_model.add(base_model)    # Nested model\n",
    "my_new_model.add(GlobalAveragePooling2D())\n",
    "my_new_model.add(Dropout(0.2))\n",
    "my_new_model.add(Dense(1, activation='sigmoid'))\n",
    "my_new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Image augmentation and Data generator\n",
    "# 5.0 We will augment/modify every image as here;\n",
    "#     src:   image array (one image)\n",
    "#     choice: A random number between 0 to 5\n",
    "#     So carry an action on image, depending upon value\n",
    "#     of 'choice'\n",
    "def augment(src, choice):\n",
    "    if choice == 0:\n",
    "        # Rotate 90\n",
    "        src = np.rot90(src, 1)\n",
    "    if choice == 1:\n",
    "        # flip vertically\n",
    "        src = np.flipud(src)\n",
    "    if choice == 2:\n",
    "        # Rotate 180\n",
    "        src = np.rot90(src, 2)\n",
    "    if choice == 3:\n",
    "        # flip horizontally\n",
    "        src = np.fliplr(src)\n",
    "    if choice == 4:\n",
    "        # Rotate 90 counter-clockwise\n",
    "        src = np.rot90(src, 3)\n",
    "    if choice == 5:\n",
    "        # Rotate 180 and flip horizontally\n",
    "        src = np.rot90(src, 2)\n",
    "        src = np.fliplr(src)\n",
    "    return src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.0 train data generator\n",
    "def train_generator():\n",
    "    while True:\n",
    "        # 6.1 'start' is incremented in steps of batch_size\n",
    "        for start in range(0, len(x_train), batch_size):\n",
    "            x_batch = []     # A list of images. Size = batch_size\n",
    "            y_batch = []\n",
    "            # 6.2 Calculate what will be our end-point\n",
    "            end = min(start + batch_size, len(x_train))\n",
    "            # 6.3 Read rows of data set x_train in batches\n",
    "            train_batch = x_train[start:end]\n",
    "            # 6.4 For every filepath and target label in every row,\n",
    "            for filepath, label in train_batch.values:\n",
    "                # 6.5 Read image of that file\n",
    "                img = cv2.imread(filepath)\n",
    "                # 6.6 Resize image\n",
    "                img = cv2.resize(img, img_size)\n",
    "                # 6.7 Send the image to augment() along with a\n",
    "                #     random number\n",
    "                img = augment(img, np.random.randint(6))\n",
    "                # 6.8 Append our image to the list\n",
    "                x_batch.append(img)\n",
    "                y_batch.append(label)\n",
    "            # 6.9 Normalize images\n",
    "            x_batch = np.array(x_batch, np.float32) / 255.\n",
    "            y_batch = np.array(y_batch, np.uint8)\n",
    "            # 6.10 x_batch is a list of batch images\n",
    "            #      And each image is of dim (img_width,img_height,3)\n",
    "            #      y_batch is a 1D array\n",
    "            yield x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 1], dtype=uint8)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7.0 Just check by using generator\n",
    "a = train_generator()\n",
    "x,y = next(a)\n",
    "x.shape     # (5, 75, 75, 3)\n",
    "y.shape     # (5,)\n",
    "x[0,...]    # Ist image, 3 channels\n",
    "x[0,...].shape   # (75, 75, 3)\n",
    "len(x)      # 5\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.1 SImilarly design validation data generator\n",
    "def valid_generator():\n",
    "    while True:\n",
    "        for start in range(0, len(x_valid), batch_size):\n",
    "            x_batch = []\n",
    "            y_batch = []\n",
    "            end = min(start + batch_size, len(x_valid))\n",
    "            valid_batch = x_valid[start:end]\n",
    "            for filepath, label in valid_batch.values:\n",
    "                img = cv2.imread(filepath)\n",
    "                img = cv2.resize(img, img_size)\n",
    "                img = augment(img, np.random.randint(6))\n",
    "                x_batch.append(img)\n",
    "                y_batch.append(label)\n",
    "            x_batch = np.array(x_batch, np.float32) / 255.\n",
    "            y_batch = np.array(y_batch, np.uint8)\n",
    "            yield x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Define Callback list\n",
    "callbacks = [\n",
    "             # 8.1 Stop training when a monitored quantity has stopped improving.\n",
    "             EarlyStopping(monitor='val_loss',\n",
    "                           patience=3,  # number of epochs with no\n",
    "                                        #  improvement after which\n",
    "                                        #   training will be stopped.\n",
    "                           verbose=1,\n",
    "                           min_delta=1e-4 # an absolute change of less\n",
    "                                          #  than min_delta, will count\n",
    "                                          #    as no improvement.\n",
    "                           ),\n",
    "            # 8.2 Models often benefit from reducing\n",
    "            #     learning rate by a factor of 2-10\n",
    "            #     once learning stagnates.\n",
    "             ReduceLROnPlateau(monitor='val_loss',\n",
    "                               factor=0.1,\n",
    "                               patience=1, # Reduce lr, if no imporvement by 'patience'\n",
    "                                           # no of epochs\n",
    "                               cooldown=1, # number of epochs to wait before resuming\n",
    "                                           # normal operation after lr has been reduced.\n",
    "                               verbose=1,\n",
    "                               min_lr=1e-7  # lower bound on the learning rate\n",
    "                               ),\n",
    "             # 8.3  Save the model after every epoch if val_loss reduces\n",
    "             ModelCheckpoint(filepath='inception.fold' +  '.hdf5',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=True\n",
    "                             )\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Compile model\n",
    "my_new_model.compile(\n",
    "                     optimizer=Adam(lr=1e-4),\n",
    "                     loss='binary_crossentropy',\n",
    "                     metrics = ['accuracy']\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Decide number of times to call each generator per epoch:\n",
    "\n",
    "train_steps = len(x_train) / batch_size\n",
    "valid_steps = len(x_valid) / batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Shree\\Shri\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/5\n",
      "400/400 [==============================] - 370s 924ms/step - loss: 0.6859 - acc: 0.5920 - val_loss: 0.6305 - val_acc: 0.6508\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.63052, saving model to inception.fold.hdf5\n",
      "Epoch 2/5\n",
      "400/400 [==============================] - 176s 439ms/step - loss: 0.6209 - acc: 0.6735 - val_loss: 0.6016 - val_acc: 0.6847\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.63052 to 0.60155, saving model to inception.fold.hdf5\n",
      "Epoch 3/5\n",
      "400/400 [==============================] - 139s 348ms/step - loss: 0.5918 - acc: 0.6860 - val_loss: 0.5706 - val_acc: 0.6644\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.60155 to 0.57058, saving model to inception.fold.hdf5\n",
      "Epoch 4/5\n",
      "400/400 [==============================] - 139s 347ms/step - loss: 0.5599 - acc: 0.7175 - val_loss: 0.5572 - val_acc: 0.6915\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.57058 to 0.55715, saving model to inception.fold.hdf5\n",
      "Epoch 5/5\n",
      "400/400 [==============================] - 139s 348ms/step - loss: 0.5362 - acc: 0.7320 - val_loss: 0.5225 - val_acc: 0.7119\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.55715 to 0.52253, saving model to inception.fold.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16.32628577152888"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10.1 And start training\n",
    "start = time.time()\n",
    "history = my_new_model.fit_generator(\n",
    "                                     train_generator(),\n",
    "                                     train_steps,\n",
    "                                     epochs=epochs,\n",
    "                                     verbose=1,\n",
    "                                     callbacks=callbacks,\n",
    "                                     validation_data=valid_generator(),\n",
    "                                     validation_steps=valid_steps\n",
    "                                     )\n",
    "\n",
    "end = time.time()\n",
    "(end-start)/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10.3\n",
    "#     How accuracy changes as epochs increase\n",
    "def plot_learning_curve():\n",
    "    val_acc = history.history['val_acc']\n",
    "    tr_acc=history.history['acc']\n",
    "    epochs = range(1, len(val_acc) +1)\n",
    "    plt.plot(epochs,val_acc, 'b', label = \"Validation accu\")\n",
    "    plt.plot(epochs, tr_acc, 'r', label = \"Training accu\")\n",
    "    plt.title(\"Training and validation accuracy\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 10.2 Plot training accuracy and validation accuracy\n",
    "plot_learning_curve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
